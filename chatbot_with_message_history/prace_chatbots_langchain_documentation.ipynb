{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/v0.2/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key =  os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000022DCDFD6E00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022DCE038A30>, root_client=<openai.OpenAI object at 0x0000022DCDF925C0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022DCDFD6F50>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm =  ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Poorna! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 12, 'total_tokens': 27, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-80670f69-590c-40cd-bdca-6a7dc6eff34f-0', usage_metadata={'input_tokens': 12, 'output_tokens': 15, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "response1 = llm.invoke([HumanMessage(content = \"my name is poorna\")])\n",
    "\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I do not know your name. Can you please tell me what your name is?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 12, 'total_tokens': 33, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b027897f-c124-4d98-a869-ef14f084927e-0', usage_metadata={'input_tokens': 12, 'output_tokens': 21, 'total_tokens': 33, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = llm.invoke([HumanMessage(content = \"what is my name?\")])\n",
    "\n",
    "response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above responses from the model we can understand that the chatbot is not able to remember the past conversation.\n",
    "\n",
    "we use AIMessage of langchain_core.messages module and pass AIMessage which is the output of previous question response while asking the chatbot for response2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Poorna.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 54, 'total_tokens': 60, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-300f3211-23ed-4185-9c95-5823475e69ae-0', usage_metadata={'input_tokens': 54, 'output_tokens': 6, 'total_tokens': 60, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(content = 'Hey my  name is poorna and am a huge fan of YS Jagan Mohan Reddy'),\n",
    "    AIMessage(content=\"Hello Poorna! \\n\\nIt's nice to meet you. \"),\n",
    "    HumanMessage(content = \"what is my name?\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after passing the aimessage as one of the messages and continuing the conversation, the chatbot can remember the past conversation and generate more accurate responses. \n",
    "\n",
    "But we can't pass it manually every single time. So ,we cna use message_history which can track both input and output messages of the model and can store them in a datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great to hear! YS Jagan Mohan Reddy is a popular political figure in India. What do you admire most about him?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 21, 'total_tokens': 51, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1b60557c-be21-4067-a17b-1d205845f6f6-0', usage_metadata={'input_tokens': 21, 'output_tokens': 30, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] =  ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    llm, \n",
    "    get_session_history= get_session_history\n",
    ")\n",
    "\n",
    "# we have use config to pass into runnable every single time. This config contains information that is not part of input directly.\n",
    "\n",
    "config ={'configurable':{'session_id':'abc2'}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey am a Huge fan of YS Jagan Mohan Reddy\"),\n",
    "    ],\n",
    "    config =  config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Poorna! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 47, 'total_tokens': 58, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-28d6a31f-635a-457d-8cf4-4d4a70bcdc72-0', usage_metadata={'input_tokens': 47, 'output_tokens': 11, 'total_tokens': 58, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are an helpful AI assistant. answer all the qquestions to your ability.'),\n",
    "        ('user','{input}')\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "chain =  prompt|llm\n",
    "\n",
    "chain.invoke([\n",
    "    HumanMessage(content = 'hey my name is poorna')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='హాయ్ పూర్ణ! YS జగన్ మోహన్ రెడ్డి గురించి మీ అభిమానిని చూస్తున్నారు. మీకు ఏ సహాయం కావాలంటే ప్రశ్నలు కోరయండి.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 48, 'total_tokens': 227, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-94b45b4f-7ce8-41e1-a35e-ff2cfb91b2de-0', usage_metadata={'input_tokens': 48, 'output_tokens': 179, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are an helpful AI assistant. answer all the qquestions to your ability in {language}'),\n",
    "        MessagesPlaceholder(variable_name = 'messages')\n",
    "    ]\n",
    ")\n",
    "chain =  prompt|llm\n",
    "chain.invoke({\n",
    "    'messages': [HumanMessage(content=\"Hi, am poorna! and a huge fan of YS Jagan Mohan Reddy\")],\n",
    "    'language': 'telugu'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='హాయ్ పూర్ణ! మీరు ఎవరి అనుయాయిని?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 121, 'total_tokens': 175, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-823efeef-e36e-4c8d-a174-39cf216a66a2-0', usage_metadata={'input_tokens': 121, 'output_tokens': 54, 'total_tokens': 175, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history= get_session_history,\n",
    "    input_messages_key= 'messages'\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'configurable': {'session_id':'chat1'}\n",
    "}\n",
    "\n",
    "response =  with_message_history.invoke({\n",
    "    'messages':[HumanMessage(content=\"Hi, am poorna! and a huge fan\")],\n",
    "    'language': 'telugu'\n",
    "    },\n",
    "    config =  config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer  = trim_messages(\n",
    "    max_tokens =50,\n",
    "    strategy = 'last',\n",
    "    token_counter = llm,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = 'human'\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry, I am not able to access personal information.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are an helpful AI assistant. answer all the qquestions to your ability in {language}'),\n",
    "        MessagesPlaceholder(variable_name = 'messages')\n",
    "    ]\n",
    ")\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter('messages')|trimmer)\n",
    "    |prompt\n",
    "    |llm\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    'messages': messages + [HumanMessage(content=\"what is my name?\")],\n",
    "    'language': 'telugu',\n",
    "})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history= get_session_history,\n",
    "    input_messages_key= 'messages',\n",
    "    input_message_key = 'messages'\n",
    ")\n",
    "\n",
    "config = {'configurable':{'session_id':'chat2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'క్షమించండి, నాకు మీ పేరు తెలియదు. మీరు మీ పేరు చెప్పండి, దయచేసి.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =  with_message_history.invoke(\n",
    "    {\n",
    "        'messages':[HumanMessage(content = 'what is my name?')],\n",
    "        'language': 'telugu'\n",
    "    },\n",
    "    config =  config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Sure|,| Todd|!| Here|'s| a| joke| for| you|:| Why| couldn|'t| the| bicycle| stand| up| by| itself|?| Because| it| was| two| tired|!||"
     ]
    }
   ],
   "source": [
    "# streaming\n",
    "\n",
    "config ={\n",
    "    'configurable':{'session_id':'chat4'}\n",
    "}\n",
    "\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        'messages': [HumanMessage(content =\" Hi! I'm todd. Tell me a joke\")],\n",
    "        'language':'english'\n",
    "    },\n",
    "    config =  config\n",
    "):\n",
    "    print(r.content, end = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

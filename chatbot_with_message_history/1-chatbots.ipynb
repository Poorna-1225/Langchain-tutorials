{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a chatbot\n",
    "\n",
    "We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation an remember previous interactions.\n",
    "\n",
    "This chatbot will be able to only use the language model to have a conversation. There are several other related concepts like\n",
    "* Conversational RAg: Enable a chatbot experience over an external source of data\n",
    "* Agents: Build a chatbot tht can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model =\"Gemma2-9b-It\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Poorna! \\n\\nIt's nice to meet you.  What kind of programming do you enjoy doing?  \\n\\nDo you have any projects you're working on right now that you'd like to talk about? ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 19, 'total_tokens': 71, 'completion_time': 0.094545455, 'prompt_time': 8.781e-05, 'queue_time': 0.01337743, 'total_time': 0.094633265}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d3e532db-4e5a-4dfe-b2be-e45991240381-0', usage_metadata={'input_tokens': 19, 'output_tokens': 52, 'total_tokens': 71})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi,My name is Poorna and a programmer\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Poorna and that you are a programmer!  \\n\\nIs there anything else you'd like to tell me about yourself? ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 88, 'total_tokens': 123, 'completion_time': 0.063636364, 'prompt_time': 0.003687259, 'queue_time': 0.01004893, 'total_time': 0.067323623}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0d542301-552a-4aad-b28d-2cc99826350d-0', usage_metadata={'input_tokens': 88, 'output_tokens': 35, 'total_tokens': 123})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi,my name is poorna and a programmer\"),\n",
    "    AIMessage(content = \"Hello Poorna! \\n\\nIt's nice to meet you.  What kind of programming do you enjoy doing?  \\n\\nDo you have any projects you're working on right now that you'd like to talk about?\"),\n",
    "    HumanMessage(content = \"hey what's my name and what do i do?\")\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LangChain chatbot development, message history is a crucial component that enables the chatbot to maintain context and understand the flow of conversation. It's essentially a record of the past interactions between the user and the chatbot, including both the user's messages and the chatbot's responses.\n",
    "\n",
    "**How message history is used:**\n",
    "\n",
    "* **Contextual awareness:** By referring to the message history, the chatbot can understand the ongoing conversation and avoid repetitive or irrelevant responses. It allows the chatbot to \"remember\" what has been said earlier and use that information to generate more meaningful and coherent replies.\n",
    "* **Personalized responses:** Message history helps the chatbot to learn about the user's preferences, interests, and communication style over time. This allows the chatbot to tailor its responses to the individual user, making the interaction more personalized and engaging.\n",
    "* **Multi-turn conversations:** Message history is essential for supporting multi-turn conversations where the user and the chatbot exchange multiple messages back and forth. It enables the chatbot to follow the thread of the conversation and maintain a consistent dialogue.\n",
    "* **Improved accuracy:** By considering the context provided by the message history, the chatbot can generate more accurate and relevant responses. This is particularly important for complex or ambiguous queries where the user's intent may not be clear from a single message.\n",
    "\n",
    "**Implementing message history in LangChain:**\n",
    "\n",
    "LangChain provides several ways to incorporate message history into your chatbot:\n",
    "\n",
    "* **`RunnableWithMessageHistory`:** This class allows you to add message history to certain types of chains. It wraps another Runnable and manages the chat message history for it.\n",
    "* **`LangGraph`:** This feature provides a built-in persistence layer, allowing chain states, including message history, to be automatically persisted in memory or external backends like SQLite, Postgres, or Redis.\n",
    "* **Custom implementations:** You can also implement your own message history management using lists or other data structures to store and access past messages.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RunnableWithMessageHistory\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "runnable_with_history = RunnableWithMessageHistory(chat_model)\n",
    "\n",
    "# Initialize the conversation\n",
    "runnable_with_history.run(HumanMessage(content=\"Hi!\"))\n",
    "\n",
    "# Continue the conversation\n",
    "response = runnable_with_history.run(HumanMessage(content=\"What's my name?\"))\n",
    "print(response)\n",
    "```\n",
    "\n",
    "In this example, `RunnableWithMessageHistory` keeps track of the conversation history, allowing the chatbot to \"remember\" the initial greeting and respond appropriately to the second message.\n",
    "\n",
    "By effectively utilizing message history, you can create more engaging, personalized, and contextually aware chatbots with LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history =  RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat1'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Poorna! It's great to meet you.  \\n\\nIt's fantastic that you're such a big fan of YS Jagan Mohan Reddy. What do you admire most about him and his work?  \\n\\nI'm always interested in hearing about what motivates people's political passions. ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 212, 'total_tokens': 279, 'completion_time': 0.121818182, 'prompt_time': 0.008365234, 'queue_time': 0.007126736000000002, 'total_time': 0.130183416}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3a3403bc-6642-4690-8d44-cff935577df8-0', usage_metadata={'input_tokens': 212, 'output_tokens': 67, 'total_tokens': 279})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = 'Hi, My name is Poorna and am the biggest fan of YS Jagan Mohan Reddy.'),\n",
    "        \n",
    "    ],config = config\n",
    "\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Poorna! It's great to meet you.  \\n\\nIt's fantastic that you're such a big fan of YS Jagan Mohan Reddy. What do you admire most about him and his work?  \\n\\nI'm always interested in hearing about what motivates people's political passions. ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You've said you are the biggest fan of YS Jagan Mohan Reddy.  \\n\\nIt seems you admire him the most! ðŸ˜Š  \\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 431, 'total_tokens': 463, 'completion_time': 0.058181818, 'prompt_time': 0.017182446, 'queue_time': 0.002578740999999999, 'total_time': 0.075364264}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3773e560-9d11-446b-a3c7-c04e0def1086-0', usage_metadata={'input_tokens': 431, 'output_tokens': 32, 'total_tokens': 463})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \" Whom do i admire most?\"),\n",
    "    ],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to any personal information about you, including your name.\\n\\nIf you'd like to tell me your name, I'd be happy to know! ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config ---> changing the seession_id\n",
    "config1 = {'configurable':{'session_id':'chat2'}}\n",
    "\n",
    "result = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content =\"what is my name?\")\n",
    "    ],\n",
    "    config = config1\n",
    ")\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
